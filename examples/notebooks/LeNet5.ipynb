{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7edc08c5-7ce4-45da-b5be-94a5343c8348",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T14:02:33.778170Z",
     "start_time": "2024-01-15T14:02:14.038020Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86d1fa5d1569dd7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T14:04:01.767878Z",
     "start_time": "2024-01-15T14:02:33.784623Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3662 - accuracy: 0.9204\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0900 - accuracy: 0.9728\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0701 - accuracy: 0.9788\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0585 - accuracy: 0.9831\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0514 - accuracy: 0.9844\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0461 - accuracy: 0.9866\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0371 - accuracy: 0.9887\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0383 - accuracy: 0.9891\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0313 - accuracy: 0.9909\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0317 - accuracy: 0.9908\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0692 - accuracy: 0.9823\n"
     ]
    }
   ],
   "source": [
    "# Train LetNet-5 on MNIST dataset\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize the data\n",
    "x_train = x_train #/ 255.0\n",
    "x_test = x_test #/ 255.0\n",
    "\n",
    "# Add a channels dimension\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "\n",
    "# Shuffle the data\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "\n",
    "# Create the model\n",
    "\n",
    "# Define the LeNet-5 model\n",
    "lenet_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=6, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(5, 5), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=120, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=84, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "lenet_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "lenet_model.fit(train_ds, epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "lenet_model.evaluate(test_ds)\n",
    "\n",
    "# Save the model\n",
    "lenet_model.save('lenet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "27af7eba-bde0-44cb-9c37-f98f39e07d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.asarray(x_train[::10], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "233a716e443ac436",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/j_/1kx7__wx15d4bvtts4f0h18r0000gq/T/tmp3a61zpgf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/j_/1kx7__wx15d4bvtts4f0h18r0000gq/T/tmp3a61zpgf/assets\n",
      "2024-01-17 02:43:51.669698: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:363] Ignored output_format.\n",
      "2024-01-17 02:43:51.669714: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:366] Ignored drop_control_dependency.\n",
      "2024-01-17 02:43:51.669836: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /var/folders/j_/1kx7__wx15d4bvtts4f0h18r0000gq/T/tmp3a61zpgf\n",
      "2024-01-17 02:43:51.671707: I tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2024-01-17 02:43:51.671719: I tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /var/folders/j_/1kx7__wx15d4bvtts4f0h18r0000gq/T/tmp3a61zpgf\n",
      "2024-01-17 02:43:51.681101: I tensorflow/cc/saved_model/loader.cc:210] Restoring SavedModel bundle.\n",
      "2024-01-17 02:43:51.735203: I tensorflow/cc/saved_model/loader.cc:194] Running initialization op on SavedModel bundle at path: /var/folders/j_/1kx7__wx15d4bvtts4f0h18r0000gq/T/tmp3a61zpgf\n",
      "2024-01-17 02:43:51.753298: I tensorflow/cc/saved_model/loader.cc:283] SavedModel load for tags { serve }; Status: success: OK. Took 83463 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/j_/1kx7__wx15d4bvtts4f0h18r0000gq/T/tmp0ojad0wp/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/j_/1kx7__wx15d4bvtts4f0h18r0000gq/T/tmp0ojad0wp/assets\n",
      "2024-01-17 02:43:54.926079: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:363] Ignored output_format.\n",
      "2024-01-17 02:43:54.926097: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:366] Ignored drop_control_dependency.\n",
      "2024-01-17 02:43:54.926222: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /var/folders/j_/1kx7__wx15d4bvtts4f0h18r0000gq/T/tmp0ojad0wp\n",
      "2024-01-17 02:43:54.928019: I tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2024-01-17 02:43:54.928034: I tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /var/folders/j_/1kx7__wx15d4bvtts4f0h18r0000gq/T/tmp0ojad0wp\n",
      "2024-01-17 02:43:54.937417: I tensorflow/cc/saved_model/loader.cc:210] Restoring SavedModel bundle.\n",
      "2024-01-17 02:43:54.990329: I tensorflow/cc/saved_model/loader.cc:194] Running initialization op on SavedModel bundle at path: /var/folders/j_/1kx7__wx15d4bvtts4f0h18r0000gq/T/tmp0ojad0wp\n",
      "2024-01-17 02:43:55.006109: I tensorflow/cc/saved_model/loader.cc:283] SavedModel load for tags { serve }; Status: success: OK. Took 79888 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 3, output_inference_type: 3\n"
     ]
    }
   ],
   "source": [
    "# Convert to TFLite (float32)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(lenet_model)\n",
    "tflite_model_float32 = converter.convert()\n",
    "\n",
    "# Save the float32 model\n",
    "with open('model_float32.tflite', 'wb') as f:\n",
    "    f.write(tflite_model_float32)\n",
    "\n",
    "# Convert to TFLite (int8)\n",
    "def representative_dataset_gen():\n",
    "    for _ in range(100):  # Adjust the range according to your dataset size\n",
    "        # Provide data samples from your dataset\n",
    "        yield [input_data]  # input_data should match the input shape of your model\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(lenet_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_int8 = converter.convert()\n",
    "\n",
    "# Save the int8 model\n",
    "with open('model_int8.tflite', 'wb') as f:\n",
    "    f.write(tflite_model_int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d5e6180-2cce-430b-a1d7-18757bba122a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0064890384674072266,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d883a763c7b74585a3491889028c5b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float32 Model Results: [[8.3245204e-15 8.9493327e-13 5.3035524e-15 1.3010989e-17 3.8570120e-09\n",
      "  1.7525302e-10 1.0000000e+00 5.0880333e-24 8.3130777e-12 1.7814556e-15]]\n",
      "Int8 Model Results: [[  0   0   0   0   0   0 255   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Function to load a TFLite model\n",
    "def load_tflite_model(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        model_content = f.read()\n",
    "    interpreter = tf.lite.Interpreter(model_content=model_content)\n",
    "    interpreter.allocate_tensors()\n",
    "    return interpreter\n",
    "\n",
    "# Function to run inference\n",
    "def run_inference(interpreter, input_data):\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    # Check if input type is quantized, then transform data to uint8\n",
    "    if input_details[0]['dtype'] == np.uint8:\n",
    "        input_scale, input_zero_point = input_details[0][\"quantization\"]\n",
    "        input_data = input_data / input_scale + input_zero_point\n",
    "\n",
    "    input_data = np.array(input_data, dtype=input_details[0]['dtype'])\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    return output_data\n",
    "\n",
    "# Load the float32 and int8 models\n",
    "float32_interpreter = load_tflite_model('model_float32.tflite')\n",
    "int8_interpreter = load_tflite_model('model_int8.tflite')\n",
    "\n",
    "# Prepare your input data (modify this according to your needs)\n",
    "# Example: input_data = np.array([your_input_data])\n",
    "input_data = x_test  # Example input. Replace with real data.\n",
    "\n",
    "# Run inference\n",
    "pred_32 = []\n",
    "pred_8 = []\n",
    "for t in tqdm(input_data):\n",
    "    x = np.asarray([t])\n",
    "    float32_results = run_inference(float32_interpreter, x)\n",
    "    int8_results = run_inference(int8_interpreter, x)\n",
    "    pred_32.append(float32_results)\n",
    "    pred_8.append(int8_results)\n",
    "\n",
    "\n",
    "# Process the results as needed\n",
    "# Example: print(float32_results), print(int8_results)\n",
    "print(\"Float32 Model Results:\", float32_results)\n",
    "print(\"Int8 Model Results:\", int8_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "adacf4ba-def5-4c02-b1a4-63d906d749fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_32 = np.asarray(pred_32).argmax(axis=2)[:,0]\n",
    "y_8 = np.asarray(pred_8).argmax(axis=2)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a31752e-2789-4868-9597-1db0664cae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c1c87b8d-d243-4c0c-980b-37a53875f53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float32: 0.9822541720826299\n",
      "Int8: 0.9828215834116726\n"
     ]
    }
   ],
   "source": [
    "print(\"Float32:\", balanced_accuracy_score(y_test, y_32))\n",
    "print(\"Int8:\", balanced_accuracy_score(y_test, y_8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e923cb9-9633-4082-9771-6aef0134f192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6691fd9e-0a69-44e2-8a25-dd5531ed3828",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
